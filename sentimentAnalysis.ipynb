{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Followed this tutorial for reference: https://www.kaggle.com/code/abdmental01/emotions-analysis-gru-94",
   "id": "27aea77a8e9a74a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:46:32.398583Z",
     "start_time": "2025-05-14T13:46:32.376757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "# from textacy import preprocessing\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sequence\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequence\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pad_sequences\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:19:45.715174Z",
     "start_time": "2025-05-14T13:19:44.784350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Data \n",
    "df = pd.read_csv('/text.csv/text.csv')\n",
    "df.head()"
   ],
   "id": "58c6a900520cb7ca",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load Data \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/kaggle/input/emotions/text.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:20:06.189609Z",
     "start_time": "2025-05-14T13:20:06.155568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shape Of Data \n",
    "print(f'The Shape Of Data Is : {df.shape}')"
   ],
   "id": "70dbbf3000bb16",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Shape Of Data \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe Shape Of Data Is : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Null Values \n",
    "df.isnull().sum()"
   ],
   "id": "d62820272e3128c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Duplicates\n",
    "df.duplicated().sum()"
   ],
   "id": "b55d0d4386aa5174"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Rename Columns \n",
    "df.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)\n",
    "# Dropping the Index Colums\n",
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ],
   "id": "d4e7bc9f6788bd15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Head Of Data\n",
    "df.head()"
   ],
   "id": "dd13e1c58ff34e63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Lets Rename Label also {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
    "df['Label'] = df['Label'].replace(0,'Sadness')\n",
    "df['Label'] = df['Label'].replace(1,'Joy')\n",
    "df['Label'] = df['Label'].replace(2,'Love')\n",
    "df['Label'] = df['Label'].replace(3,'Anger')\n",
    "df['Label'] = df['Label'].replace(4,'Fear')\n",
    "df['Label'] = df['Label'].replace(5,'Surprise')"
   ],
   "id": "91bdb5c3b4c28acf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Value Count Of Label\n",
    "count = df['Label'].value_counts()\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6), facecolor='white')\n",
    "\n",
    "# Plot pie chart on the first subplot\n",
    "palette = sns.color_palette(\"viridis\")\n",
    "sns.set_palette(palette)\n",
    "axs[0].pie(count, labels=count.index, autopct='%1.1f%%', startangle=140)\n",
    "axs[0].set_title('Distribution of Categories')\n",
    "\n",
    "# Plot bar chart on the second subplot\n",
    "sns.barplot(x=count.index, y=count.values, ax=axs[1], palette=\"viridis\")\n",
    "axs[1].set_title('Count of Categories')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "af9460fed655116a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make Seperate Data Set to Visualize text \n",
    "# Sadness\n",
    "df_sadness = df[df['Label']=='Sadness']\n",
    "# Joy\n",
    "df_joy = df[df['Label']=='Joy']\n",
    "# Love\n",
    "df_love = df[df['Label']=='Love']\n",
    "# Anger\n",
    "df_anger = df[df['Label']=='Anger']\n",
    "# Fear\n",
    "df_fear = df[df['Label']=='Fear']\n",
    "# Surprise\n",
    "df_surprise = df[df['Label']=='Surprise']"
   ],
   "id": "d0c6f3735e17a73f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine text from different categories\n",
    "combined_sadness_text = ' '.join(df_sadness['Text'])\n",
    "combined_joy_text = ' '.join(df_joy['Text'])\n",
    "combined_love_text = ' '.join(df_love['Text'])\n",
    "combined_anger_text = ' '.join(df_anger['Text'])\n",
    "combined_fear_text = ' '.join(df_fear['Text'])\n",
    "combined_surprise_text = ' '.join(df_surprise['Text'])\n",
    "\n",
    "# Create word clouds\n",
    "sadness_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_sadness_text)\n",
    "joy_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_joy_text)\n",
    "love_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_love_text)\n",
    "anger_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_anger_text)\n",
    "fear_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_fear_text)\n",
    "surprise_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_surprise_text)\n",
    "# Plot the word clouds\n",
    "plt.figure(figsize=(18, 9))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(sadness_wordcloud, interpolation='bilinear')\n",
    "plt.title('Sadness Text')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(joy_wordcloud, interpolation='bilinear')\n",
    "plt.title('Joy Text')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(love_wordcloud, interpolation='bilinear')\n",
    "plt.title('Love Text')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(anger_wordcloud, interpolation='bilinear')\n",
    "plt.title('Anger Text')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(fear_wordcloud, interpolation='bilinear')\n",
    "plt.title('Fear Text')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(surprise_wordcloud, interpolation='bilinear')\n",
    "plt.title('Surprise Text')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4b447cb6208322db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now Unrename Label again\n",
    "df['Label'] = df['Label'].replace('Sadness',0)\n",
    "df['Label'] = df['Label'].replace('Joy',1)\n",
    "df['Label'] = df['Label'].replace('Love',2)\n",
    "df['Label'] = df['Label'].replace('Anger',3)\n",
    "df['Label'] = df['Label'].replace('Fear',4)\n",
    "df['Label'] = df['Label'].replace('Surprise',5)"
   ],
   "id": "f7e95948a1b5759a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import Basis Needed Libaries \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download NLTK resources (uncomment the following line if not already downloaded)?\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ],
   "id": "50d054e59aac6c17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1: Remove URLs\n",
    "df['Text'] = df['Text'].str.replace(r'http\\S+', '', regex=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ],
   "id": "bf4d8281724f03ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 2: Remove special characters and punctuation\n",
    "df['Text'] = df['Text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ],
   "id": "d931bb4112ee833"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 3: Remove extra whitespaces\n",
    "df['Text'] = df['Text'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ],
   "id": "ca96a94417feecc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step : 4 Remove numeric values\n",
    "df['Text'] = df['Text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# Head\n",
    "df.head()"
   ],
   "id": "1d3188cf13aac191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 6: Lowercasing\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ],
   "id": "b7b4916b088b914"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 8: Remove stop words\n",
    "stop = stopwords.words('english')\n",
    "df[\"Text\"] = df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "df.head()"
   ],
   "id": "a754a4fb443d7372"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step : 9 Remove non-alphanumeric characters from the 'Text' column\n",
    "df['Text'] = df['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "df.head()"
   ],
   "id": "7a2a277145daa50a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = df['Text']\n",
    "y = df['Label']\n",
    "\n",
    "# Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ],
   "id": "c6b8e4cdeac3a040"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=50000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ],
   "id": "696328f6294c31f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Max Len in X_train_sequences\n",
    "maxlen = max(len(tokens) for tokens in X_train_sequences)\n",
    "print(\"Maximum sequence length (maxlen):\", maxlen)"
   ],
   "id": "37f71416a69294ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Perform padding on X_train and X_test sequences\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=maxlen, padding='post',)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=maxlen, padding='post')\n",
    "\n",
    "# Print the padded sequences for X_train and X_test\n",
    "print(\"X_train_padded:\")\n",
    "print(X_train_padded)\n",
    "print(\"\\nX_test_padded:\")\n",
    "print(X_test_padded)"
   ],
   "id": "bf535176ced2900"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Embedding Input Size / Vocabulary Size \n",
    "input_Size = np.max(X_train_padded) + 1\n",
    "input_Size"
   ],
   "id": "6bff9aedfc2d711b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add embedding layer\n",
    "model.add(Embedding(input_dim=input_Size, output_dim=50, input_length=maxlen))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add Bidirectional LSTM layer\n",
    "model.add(Bidirectional(GRU(120, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(64, return_sequences=True)))\n",
    "\n",
    "#Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add Bidirectional GRU layer\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ],
   "id": "d2b0fbcbecdbad86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Model Train \n",
    "history = model.fit(X_train_padded, y_train, epochs=5, batch_size=1500, validation_data=(X_test_padded, y_test))"
   ],
   "id": "9e499692231c7cb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the epoch with the highest validation accuracy\n",
    "best_epoch = history.history['val_accuracy'].index(max(history.history['val_accuracy'])) + 1\n",
    "\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "axs[0].scatter(best_epoch - 1, history.history['val_accuracy'][best_epoch - 1], color='green', label=f'Best Epoch: {best_epoch}')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_title('Training and Validation Accuracy')\n",
    "axs[0].legend()\n",
    "# Plot training and validation loss\n",
    "axs[1].plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "axs[1].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "axs[1].scatter(best_epoch - 1, history.history['val_loss'][best_epoch - 1], color='green',label=f'Best Epoch: {best_epoch}')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_title('Training and Validation Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "dc409ebfad7cb573"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate Test Data \n",
    "model.evaluate(X_test_padded, y_test)"
   ],
   "id": "bc77837869b3cf0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Predictions On Test For Confustion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ],
   "id": "c14d0a3b573b906f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds')"
   ],
   "id": "f68e2b75247d2d05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
